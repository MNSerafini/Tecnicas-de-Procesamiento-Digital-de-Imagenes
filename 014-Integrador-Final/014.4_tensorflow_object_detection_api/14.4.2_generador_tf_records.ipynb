{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1I3-P0fWmveA"
   },
   "source": [
    "#Modelo con TensorFlow OD API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3ocLV-a2muVa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 22:37:40.072568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750556260.274201  251499 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750556260.327334  251499 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750556260.786048  251499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750556260.786088  251499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750556260.786090  251499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750556260.786092  251499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-21 22:37:40.833894: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Importamos librerias Necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image, ImageFilter, ImageDraw, ImageFont\n",
    "#from IPython.display import Image as ImageDisplay\n",
    "#from IPython.core.display import HTML\n",
    "#from IPython.display import display, Image as IPImage\n",
    "#from io import BytesIO\n",
    "#import base64\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wFMlFkuqnngt"
   },
   "outputs": [],
   "source": [
    "imagenes_np = np.load('/home/garzamorada/my_character_detector_workspace/ocr_font_images_dataset.npy', allow_pickle=True)\n",
    "imagenes_df = pd.read_csv('/home/garzamorada/my_character_detector_workspace/ocr_font_labels_dataset.csv')\n",
    "path_tfrecord = '/home/garzamorada/my_character_detector_workspace/eval/tfrecord'\n",
    "os.makedirs(path_tfrecord, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Mdx5u1tuumJi"
   },
   "outputs": [],
   "source": [
    "caracteres = \"ABCDEFGHIJKLMNOPQRSTUVWXYZÑabcdefghijklmnopqrstuvwxyzñáéíóúü0123456789.,;:?¿!¡-—&*/+=-_@#$%\"\n",
    "\n",
    "# Eliminar duplicados preservando orden\n",
    "caracteres = ''.join(dict.fromkeys(caracteres))\n",
    "\n",
    "label_list = [{\"id\": idx, \"label\": c} for idx, c in enumerate(caracteres, start=1)]\n",
    "\n",
    "\n",
    "def get_id_by_char(label, labels=label_list):\n",
    "    for item in labels:\n",
    "        if item[\"label\"] == label:\n",
    "            return item[\"id\"]\n",
    "    return None\n",
    "\n",
    "def generar_label_map(label_list, ruta_archivo):\n",
    "    with open(ruta_archivo, 'w', encoding='utf-8') as f:\n",
    "        for item in label_list:\n",
    "            f.write(\"item {\\n\")\n",
    "            f.write(f\"  id: {item['id']}\\n\")\n",
    "            f.write(f\"  name: '{item['label']}'\\n\")\n",
    "            f.write(\"}\\n\")\n",
    "\n",
    "generar_label_map(label_list, \"/home/garzamorada/my_character_detector_workspace/label_map.pbtxt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5YLZAJPoeuL"
   },
   "source": [
    "## Generador de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Z9gTIUd-oxnu"
   },
   "outputs": [],
   "source": [
    "# Generador de tfrecord\n",
    "def guardar_imagen_y_tfrecord(imagen_np, bboxes, labels, chars, output_dir, nombre_base='img', idx=0):\n",
    "    \"\"\"\n",
    "    Guarda una imagen en disco y genera un archivo TFRecord correspondiente.\n",
    "\n",
    "    Args:\n",
    "        imagen_np: np.ndarray (H, W) en escala de grises.\n",
    "        bboxes: lista de bboxes en formato [xmin, ymin, xmax, ymax].\n",
    "        labels: lista de strings de etiquetas correspondientes a cada bbox.\n",
    "        output_dir: carpeta donde guardar los archivos.\n",
    "        nombre_base: nombre base para los archivos (ej: 'img' → img_001.png).\n",
    "        idx: índice numérico único para el nombre de archivo.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Guardar imagen en PNG\n",
    "    filename = f'{nombre_base}_{idx:04d}.png'\n",
    "    path_imagen = os.path.join(output_dir, filename)\n",
    "    Image.fromarray(imagen_np).save(path_imagen)\n",
    "\n",
    "    # 2. Codificar imagen\n",
    "    with tf.io.gfile.GFile(path_imagen, 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "    height, width = imagen_np.shape\n",
    "\n",
    "    # 3. Normalizar bboxes\n",
    "    xmins = [box[0] / width for box in bboxes]\n",
    "    xmaxs = [box[2] / width for box in bboxes]\n",
    "    ymins = [box[1] / height for box in bboxes]\n",
    "    ymaxs = [box[3] / height for box in bboxes]\n",
    "    classes_text = [char.encode('utf8') for char in chars]\n",
    "    classes_ids = labels\n",
    "\n",
    "    # 4. Crear TF Example\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'png'])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes_ids)),\n",
    "    }))\n",
    "\n",
    "    # 5. Guardar TFRecord\n",
    "    tfrecord_path = os.path.join(output_dir, f'{nombre_base}_{idx:04d}.tfrecord')\n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    return path_imagen, tfrecord_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6DnKFsiUGYO0"
   },
   "outputs": [],
   "source": [
    "# --- 1. Funciones para Generar Fondos Grandes (224x224px) ---\n",
    "def create_noise_background(image_shape, gray_center=128, noise_amplitude=50):\n",
    "    \"\"\"\n",
    "    Crea un fondo de ruido aleatorio predominantemente gris, con cierta variación.\n",
    "\n",
    "    Args:\n",
    "        image_shape (tuple): Las dimensiones (altura, anchura) de la imagen.\n",
    "        gray_center (int): El valor central de gris para el ruido (0-255).\n",
    "        noise_amplitude (int): La amplitud del ruido alrededor del centro.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Un array NumPy que representa el fondo de ruido.\n",
    "    \"\"\"\n",
    "    min_val = max(0, gray_center - noise_amplitude)\n",
    "    max_val = min(255, gray_center + noise_amplitude)\n",
    "    noise = np.random.randint(min_val, max_val + 1, image_shape, dtype=np.uint8)\n",
    "    return noise\n",
    "\n",
    "def create_large_background(img_size=(640, 640), bg_type=\"white\"):\n",
    "    \"\"\"\n",
    "    Crea un fondo grande (224x224) del tipo especificado.\n",
    "\n",
    "    Args:\n",
    "        img_size (tuple): Dimensiones de la imagen de fondo (ancho, alto).\n",
    "        bg_type (str): Tipo de fondo ('white', 'black', 'gray', 'noise').\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Imagen de fondo en escala de grises.\n",
    "    \"\"\"\n",
    "    if bg_type == \"white\":\n",
    "        return np.full(img_size, 255, dtype=np.uint8)\n",
    "    elif bg_type == \"black\":\n",
    "        return np.full(img_size, 0, dtype=np.uint8)\n",
    "    elif bg_type == \"gray\":\n",
    "        return np.full(img_size, 128, dtype=np.uint8)\n",
    "    elif bg_type == \"noise\":\n",
    "        return create_noise_background(img_size) # Usa la función de ruido con parámetros por defecto\n",
    "    else:\n",
    "        raise ValueError(\"Tipo de fondo no reconocido. Use 'white', 'black', 'gray', 'noise'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "00PifarsGj_c"
   },
   "outputs": [],
   "source": [
    "# --- 2. Función para Obtener Posiciones sin Solapamiento ---\n",
    "\n",
    "def get_non_overlapping_positions(\n",
    "    num_chars,\n",
    "    char_size=(32, 32), # Tamaño de cada carácter de tu dataset original\n",
    "    large_img_size=(640, 640), # Tamaño de la imagen de salida\n",
    "    layout_type=\"random\", # Tipos de disposición: 'random', '1_row', '2_rows', '1_column'\n",
    "    padding=0 # Espacio mínimo entre caracteres\n",
    "):\n",
    "    \"\"\"\n",
    "    Calcula posiciones para caracteres sin solapamiento dentro de una imagen grande.\n",
    "\n",
    "    Args:\n",
    "        num_chars (int): Número de caracteres a posicionar.\n",
    "        char_size (tuple): Dimensiones de cada carácter (ancho, alto).\n",
    "        large_img_size (tuple): Dimensiones de la imagen grande (ancho, alto).\n",
    "        layout_type (str): Tipo de disposición ('random', '1_row', '2_rows', '1_column').\n",
    "        padding (int): Espacio mínimo en píxeles entre los caracteres y los bordes.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de tuplas (x, y) para cada posición del carácter (esquina superior izquierda).\n",
    "              Retorna [] si no se pueden colocar todos los caracteres solicitados.\n",
    "    \"\"\"\n",
    "\n",
    "    char_w, char_h = char_size\n",
    "    img_w, img_h = large_img_size\n",
    "    positions = []\n",
    "    placed_bboxes = [] # Almacena (x, y, x+w, y+h) de los caracteres ya colocados, incluyendo padding\n",
    "\n",
    "    # Función auxiliar para verificar solapamiento con padding\n",
    "    def is_overlapping(new_x, new_y):\n",
    "        # Bbox del nuevo caracter incluyendo el padding\n",
    "        new_bbox_padded = (new_x - padding, new_y - padding,\n",
    "                           new_x + char_w + padding, new_y + char_h + padding)\n",
    "\n",
    "        for p_bbox_padded in placed_bboxes:\n",
    "            # Check for overlap (AABB intersection)\n",
    "            if not (new_bbox_padded[2] < p_bbox_padded[0] or\n",
    "                    new_bbox_padded[0] > p_bbox_padded[2] or\n",
    "                    new_bbox_padded[3] < p_bbox_padded[1] or\n",
    "                    new_bbox_padded[1] > p_bbox_padded[3]):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    if num_chars == 0:\n",
    "        return []\n",
    "\n",
    "    if layout_type == \"1_row\":\n",
    "        total_width_needed = num_chars * (char_w + padding)\n",
    "        if total_width_needed > img_w:\n",
    "            num_chars = int(img_w / (char_w + padding)) - 1\n",
    "            total_width_needed = num_chars * (char_w + padding)\n",
    "\n",
    "        start_x = (img_w - total_width_needed) // 2\n",
    "        y = (img_h - char_h) // 2 # Centrado vertical\n",
    "        for i in range(num_chars):\n",
    "            x = start_x + i * (char_w + padding)\n",
    "            positions.append((x, y))\n",
    "            placed_bboxes.append((x, y, x + char_w, y + char_h)) # Guardamos el bbox real, is_overlapping usa su propia versión con padding\n",
    "\n",
    "    elif layout_type == \"2_rows\":\n",
    "        # Distribuir caracteres entre las dos filas\n",
    "        chars_per_row_upper = (num_chars + 1) // 2\n",
    "        chars_per_row_lower = num_chars // 2 # Opcion 1: para num_chars impar, la fila superior tiene 1 más.\n",
    "                                            # Opcion 2: chars_per_row_lower = num_chars - chars_per_row_upper;\n",
    "\n",
    "        total_width_upper = chars_per_row_upper * (char_w + padding)\n",
    "        total_width_lower = chars_per_row_lower * (char_w + padding)\n",
    "\n",
    "        if max(total_width_upper, total_width_lower) > img_w or (char_h * 2 + padding) > img_h:\n",
    "            num_chars = (int(img_w / (char_w + padding)) - 1)*2\n",
    "            chars_per_row_upper = (num_chars) // 2\n",
    "            chars_per_row_lower = num_chars // 2 # Opcion 1: para num_chars impar, la fila superior tiene 1 más.\n",
    "                                            # Opcion 2: chars_per_row_lower = num_chars - chars_per_row_upper;\n",
    "            total_width_upper = chars_per_row_upper * (char_w + padding)\n",
    "            total_width_lower = chars_per_row_lower * (char_w + padding)\n",
    "\n",
    "        # Calcular alturas de las filas (distribución equitativa o fija)\n",
    "        # Aquí, las dos filas se centran verticalmente dentro del espacio total.\n",
    "        total_content_height = char_h * 2 + padding # Dos alturas de caracter mas un padding entre ellas\n",
    "        start_y = (img_h - total_content_height) // 2\n",
    "\n",
    "        y_upper = start_y\n",
    "        y_lower = start_y + char_h + padding\n",
    "\n",
    "        # Posicionar en fila superior\n",
    "        start_x_upper = (img_w - total_width_upper) // 2\n",
    "        for i in range(chars_per_row_upper):\n",
    "            x = start_x_upper + i * (char_w + padding)\n",
    "            positions.append((x, y_upper))\n",
    "            placed_bboxes.append((x, y_upper, x + char_w, y_upper + char_h))\n",
    "\n",
    "        # Posicionar en fila inferior\n",
    "        start_x_lower = (img_w - total_width_lower) // 2\n",
    "        for i in range(chars_per_row_lower):\n",
    "            x = start_x_lower + i * (char_w + padding)\n",
    "            positions.append((x, y_lower))\n",
    "            placed_bboxes.append((x, y_lower, x + char_w, y_lower + char_h))\n",
    "\n",
    "    elif layout_type == \"1_column\":\n",
    "        total_height_needed = num_chars * (char_h + padding)\n",
    "        if total_height_needed > img_h:\n",
    "            num_chars = int(img_h / (char_h + padding)) - 1\n",
    "            total_height_needed = num_chars * (char_h + padding)\n",
    "\n",
    "        x = (img_w - char_w) // 2 # Centrado horizontal\n",
    "        start_y = (img_h - total_height_needed) // 2\n",
    "        for i in range(num_chars):\n",
    "            y = start_y + i * (char_h + padding)\n",
    "            positions.append((x, y))\n",
    "            placed_bboxes.append((x, y, x + char_w, y + char_h))\n",
    "\n",
    "    elif layout_type == \"random\":\n",
    "        # Asegurarse de que el tamaño de la imagen grande sea divisible por el tamaño del caracter\n",
    "\n",
    "        grid_cols = img_w // char_w\n",
    "        grid_rows = img_h // char_h\n",
    "\n",
    "        total_grid_cells = grid_cols * grid_rows\n",
    "\n",
    "        if num_chars > total_grid_cells:\n",
    "            num_chars = total_grid_cells // 2\n",
    "\n",
    "        # Seleccionar celdas de la grilla al azar sin repetición\n",
    "        selected_cell_indices = random.sample(range(total_grid_cells), num_chars)\n",
    "\n",
    "        for cell_idx in selected_cell_indices:\n",
    "            row = cell_idx // grid_cols\n",
    "            col = cell_idx % grid_cols\n",
    "\n",
    "            x = col * char_w\n",
    "            y = row * char_h\n",
    "            positions.append((x, y))\n",
    "    else:\n",
    "        raise ValueError(\"Tipo de disposición no reconocido. Use 'random', '1_row', '2_rows', '1_column'.\")\n",
    "\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "u5XgSbqqGwwb"
   },
   "outputs": [],
   "source": [
    "def generate_composed_dataset(\n",
    "    original_numpy_dataset, original_pandas_dataset,\n",
    "    output_img_count, # Número de imágenes compuestas a generar\n",
    "    min_chars_per_img=0,\n",
    "    max_chars_per_img=10,\n",
    "    large_img_size=(640, 640),\n",
    "    char_size=(64, 64), # Este es el tamaño fijo de tus caracteres originales\n",
    "    background_types=[\"white\", \"black\", \"gray\", \"noise\"],\n",
    "    layout_types=[\"random\", \"1_row\", \"2_rows\", \"1_column\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera un nuevo dataset de imágenes compuestas (224x224) con múltiples caracteres (32x32).\n",
    "\n",
    "    Args:\n",
    "        original_numpy_dataset (np.ndarray): Tu dataset de NumPy con caracteres individuales (32x32).\n",
    "        output_img_count (int): Número de imágenes grandes a generar.\n",
    "        min_chars_per_img (int): Mínimo de caracteres a insertar por imagen grande.\n",
    "        max_chars_per_img (int): Máximo de caracteres a insertar por imagen grande.\n",
    "        large_img_size (tuple): Dimensiones de las imágenes de salida (ancho, alto).\n",
    "        char_size (tuple): Dimensiones de los caracteres individuales (ancho, alto).\n",
    "        background_types (list): Tipos de fondo para las imágenes grandes.\n",
    "        layout_types (list): Tipos de disposición de caracteres dentro de la imagen grande.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (composed_numpy_dataset, composed_pandas_dataset)\n",
    "               composed_numpy_dataset: Array NumPy con imágenes compuestas y sus bboxes adaptados.\n",
    "               composed_pandas_dataset: DataFrame de Pandas con metadatos de cada imagen compuesta.\n",
    "    \"\"\"\n",
    "\n",
    "    composed_numpy_data = [] # Lista para los elementos del nuevo NumPy dataset\n",
    "    composed_pandas_data = [] # Lista para los elementos del nuevo Pandas DataFrame\n",
    "    global_composed_index = 0\n",
    "\n",
    "    nominal_char_w, nominal_char_h = char_size\n",
    "\n",
    "    if original_numpy_dataset.size == 0:\n",
    "        print(\"El dataset de caracteres original está vacío. No se pueden generar imágenes compuestas.\")\n",
    "        return np.array([], dtype=[('image', object), ('bboxes', object), ('index', int)]), pd.DataFrame()\n",
    "\n",
    "    for _ in range(output_img_count):\n",
    "        if ((global_composed_index + 1) * 100) % output_img_count == 0:\n",
    "            print(f\"realizado {((global_composed_index + 1) * 100) // output_img_count}% \")\n",
    "        num_chars_to_place = random.randint(min_chars_per_img, max_chars_per_img)\n",
    "\n",
    "        # 1. Elegir tipo de fondo y generarlo\n",
    "        #bg_type = random.choice(background_types)\n",
    "        bg_type = 'black'\n",
    "        background_img = create_large_background(large_img_size, bg_type)\n",
    "        composed_image = background_img.copy()\n",
    "\n",
    "        # 2. Elegir tipo de disposición y obtener posiciones\n",
    "        layout_type = random.choice(layout_types)\n",
    "        char_positions = get_non_overlapping_positions(\n",
    "            num_chars_to_place, char_size, large_img_size, layout_type\n",
    "        )\n",
    "\n",
    "        num_chars_effectively_placed = len(char_positions)\n",
    "        current_image_bboxes = [] # Almacenará los bboxes adaptados para esta imagen grande\n",
    "\n",
    "        # 3. Seleccionar caracteres del dataset original y colocarlos\n",
    "        # Solo seleccionamos el número de caracteres que realmente pudimos posicionar\n",
    "        selected_char_indices = random.sample(\n",
    "            range(original_numpy_dataset.shape[0]), min(num_chars_effectively_placed, original_numpy_dataset.shape[0])\n",
    "        )\n",
    "        labels=[]\n",
    "        chars=[]\n",
    "        for i, pos in enumerate(char_positions):\n",
    "            if i >= len(selected_char_indices): # En caso de que se hayan encontrado más posiciones que caracteres seleccionados\n",
    "                break\n",
    "\n",
    "            char_data_index = selected_char_indices[i]\n",
    "            char_entry = original_numpy_dataset[char_data_index]\n",
    "            char_index = char_entry['index']\n",
    "            char_data = original_pandas_dataset[original_pandas_dataset['index'] == char_index].iloc[0]\n",
    "            char_label = char_data['character']\n",
    "            chars.append(char_label)\n",
    "            id=get_id_by_char(char_label)\n",
    "            labels.append(id)\n",
    "\n",
    "            # Obtener la imagen del caracter y su bbox ORIGINAL directamente del dataset.\n",
    "            char_image = char_entry['image']    \n",
    "            char_image = cv2.resize(char_image, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "            original_char_bbox = char_entry['bbox'] # Bbox original de la imagen 32x32px\n",
    "\n",
    "            x_offset, y_offset = pos # Posición (top-left) donde pegamos la imagen 32x32px en la 224x224px\n",
    "\n",
    "            # Superponer el carácter: Asignación directa del ROI\n",
    "            # Esto copia la imagen de 32x32px tal cual (con su propio fondo)\n",
    "            # a la posición en la imagen compuesta.\n",
    "            composed_image[y_offset : y_offset + nominal_char_h, x_offset : x_offset + nominal_char_w] = char_image\n",
    "\n",
    "            # Adaptar el bbox original (de 32x32px) a la posición en la imagen grande (224x224px)\n",
    "            # Sumamos el offset de la posición donde pegamos la imagen pequeña\n",
    "            adapted_x_min = original_char_bbox[0] + x_offset\n",
    "            adapted_y_min = original_char_bbox[1] + y_offset\n",
    "            adapted_x_max = original_char_bbox[2] + x_offset\n",
    "            adapted_y_max = original_char_bbox[3] + y_offset\n",
    "\n",
    "            current_image_bboxes.append((adapted_x_min, adapted_y_min, adapted_x_max, adapted_y_max))\n",
    "\n",
    "        # 4. Añadir a los datasets de salida\n",
    "        \"\"\"composed_numpy_data.append((composed_image, current_image_bboxes, global_composed_index))\"\"\"\n",
    "\n",
    "        \"\"\"composed_pandas_data.append({\n",
    "            'index': global_composed_index,\n",
    "            'num_chars': num_chars_effectively_placed,\n",
    "            'background_type': bg_type,\n",
    "            'layout_type': layout_type,\n",
    "            'has_chars': bool(current_image_bboxes) # True si hay chars, False si no\n",
    "        })\"\"\"\n",
    "        ruta_imagen, ruta_record = guardar_imagen_y_tfrecord(composed_image, current_image_bboxes, labels, chars, path_tfrecord, nombre_base='img', idx=global_composed_index)\n",
    "\n",
    "        global_composed_index += 1\n",
    "\n",
    "    # Convertir las listas a arrays de NumPy y DataFrame de Pandas\n",
    "    # El dtype 'object' es necesario porque las imágenes y bboxes son arrays/listas de tamaño variable\n",
    "    composed_numpy_dataset = np.array(composed_numpy_data, dtype=[('image', object), ('bboxes', object), ('index', int)])\n",
    "    composed_pandas_dataset = pd.DataFrame(composed_pandas_data)\n",
    "\n",
    "    return composed_numpy_dataset, composed_pandas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yLHfyxxNrM4",
    "outputId": "225a8caa-ce60-41f4-b022-6ed805191527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realizado 1% \n",
      "realizado 2% \n",
      "realizado 3% \n",
      "realizado 4% \n",
      "realizado 5% \n",
      "realizado 6% \n",
      "realizado 7% \n",
      "realizado 8% \n",
      "realizado 9% \n",
      "realizado 10% \n",
      "realizado 11% \n",
      "realizado 12% \n",
      "realizado 13% \n",
      "realizado 14% \n",
      "realizado 15% \n",
      "realizado 16% \n",
      "realizado 17% \n",
      "realizado 18% \n",
      "realizado 19% \n",
      "realizado 20% \n",
      "realizado 21% \n",
      "realizado 22% \n",
      "realizado 23% \n",
      "realizado 24% \n",
      "realizado 25% \n",
      "realizado 26% \n",
      "realizado 27% \n",
      "realizado 28% \n",
      "realizado 29% \n",
      "realizado 30% \n",
      "realizado 31% \n",
      "realizado 32% \n",
      "realizado 33% \n",
      "realizado 34% \n",
      "realizado 35% \n",
      "realizado 36% \n",
      "realizado 37% \n",
      "realizado 38% \n",
      "realizado 39% \n",
      "realizado 40% \n",
      "realizado 41% \n",
      "realizado 42% \n",
      "realizado 43% \n",
      "realizado 44% \n",
      "realizado 45% \n",
      "realizado 46% \n",
      "realizado 47% \n",
      "realizado 48% \n",
      "realizado 49% \n",
      "realizado 50% \n",
      "realizado 51% \n",
      "realizado 52% \n",
      "realizado 53% \n",
      "realizado 54% \n",
      "realizado 55% \n",
      "realizado 56% \n",
      "realizado 57% \n",
      "realizado 58% \n",
      "realizado 59% \n",
      "realizado 60% \n",
      "realizado 61% \n",
      "realizado 62% \n",
      "realizado 63% \n",
      "realizado 64% \n",
      "realizado 65% \n",
      "realizado 66% \n",
      "realizado 67% \n",
      "realizado 68% \n",
      "realizado 69% \n",
      "realizado 70% \n",
      "realizado 71% \n",
      "realizado 72% \n",
      "realizado 73% \n",
      "realizado 74% \n",
      "realizado 75% \n",
      "realizado 76% \n",
      "realizado 77% \n",
      "realizado 78% \n",
      "realizado 79% \n",
      "realizado 80% \n",
      "realizado 81% \n",
      "realizado 82% \n",
      "realizado 83% \n",
      "realizado 84% \n",
      "realizado 85% \n",
      "realizado 86% \n",
      "realizado 87% \n",
      "realizado 88% \n",
      "realizado 89% \n",
      "realizado 90% \n",
      "realizado 91% \n",
      "realizado 92% \n",
      "realizado 93% \n",
      "realizado 94% \n",
      "realizado 95% \n",
      "realizado 96% \n",
      "realizado 97% \n",
      "realizado 98% \n",
      "realizado 99% \n",
      "realizado 100% \n"
     ]
    }
   ],
   "source": [
    "# Parámetros para la generación de imágenes compuestas\n",
    "num_composed_images_to_generate = 5000 # Define cuántas imágenes grandes quieres generar\n",
    "output_large_img_size = (640, 640)\n",
    "input_char_size = (64, 64) # Tamaño fijo de tus caracteres de origen\n",
    "min_chars_on_img = 0\n",
    "max_chars_on_img = 20\n",
    "background_options = [\"white\", \"black\", \"gray\", \"noise\"]\n",
    "layout_options = [\"random\", \"1_row\", \"2_rows\", \"1_column\"]\n",
    "original_numpy_dataset= imagenes_np\n",
    "original_pandas_dataset= imagenes_df\n",
    "\n",
    "composed_numpy_dataset, composed_pandas_dataset = generate_composed_dataset(\n",
    "    original_numpy_dataset, original_pandas_dataset,\n",
    "    num_composed_images_to_generate,\n",
    "    min_chars_per_img=min_chars_on_img,\n",
    "    max_chars_per_img=max_chars_on_img,\n",
    "    large_img_size=output_large_img_size,\n",
    "    char_size=input_char_size,\n",
    "    background_types=background_options,\n",
    "    layout_types=layout_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f-yTh9amPH_v",
    "outputId": "e7745e7f-d86b-4caf-f13e-23acf07190f8"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Elegir 10 filas al azar del composed_numpy_dataset\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Como composed_numpy_dataset es un array numpy con dtype object, no podemos usar .sample().\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Podemos obtener índices aleatorios y luego acceder a esos índices.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m---> 21\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomposed_numpy_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMostrando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m imágenes aleatorias del dataset compuesto con sus bboxes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m random_indices:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Acceder a la entrada del dataset numpy por índice\u001b[39;00m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:968\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Muestro 10 resultados al azar\n",
    "\n",
    "def draw_bboxes(image_np, bboxes):\n",
    "    \"\"\"Dibuja las bounding boxes en una imagen NumPy.\"\"\"\n",
    "    img_copy = image_np.copy()\n",
    "    # Asegúrate de que la imagen sea BGR si es escala de grises para dibujar en color\n",
    "    if len(img_copy.shape) == 2:\n",
    "        img_copy = cv2.cvtColor(img_copy, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        # bbox is (x_min, y_min, x_max, y_max)\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        # Draw rectangle with green color (0, 255, 0) and thickness 1\n",
    "        cv2.rectangle(img_copy, (x_min, y_min), (x_max, y_max), (0, 255, 0), 1)\n",
    "    return img_copy\n",
    "\n",
    "# Elegir 10 filas al azar del composed_numpy_dataset\n",
    "# Como composed_numpy_dataset es un array numpy con dtype object, no podemos usar .sample().\n",
    "# Podemos obtener índices aleatorios y luego acceder a esos índices.\n",
    "num_samples = 20\n",
    "random_indices = np.random.choice(len(composed_numpy_dataset), num_samples, replace=False)\n",
    "\n",
    "print(f\"Mostrando {num_samples} imágenes aleatorias del dataset compuesto con sus bboxes:\")\n",
    "\n",
    "for i in random_indices:\n",
    "    # Acceder a la entrada del dataset numpy por índice\n",
    "    composed_entry = composed_numpy_dataset[i]\n",
    "\n",
    "    # Obtener la imagen y la lista de bboxes\n",
    "    image = composed_entry['image']\n",
    "    bboxes = composed_entry['bboxes']\n",
    "    entry_index = composed_entry['index'] # El índice original de la entrada\n",
    "\n",
    "    # Opcional: Obtener metadatos del pandas_dataset usando el 'index'\n",
    "    pandas_row = composed_pandas_dataset[composed_pandas_dataset['index'] == entry_index].iloc[0]\n",
    "    print(f\"\\n--- Imagen Index: {entry_index} ---\")\n",
    "    print(f\"Número de caracteres: {pandas_row['num_chars']}, Fondo: {pandas_row['background_type']}, Disposición: {pandas_row['layout_type']}\")\n",
    "    print(f\"Bboxes encontrados: {len(bboxes)}\")\n",
    "\n",
    "\n",
    "    # Dibujar los bboxes en la imagen\n",
    "    image_with_bboxes = draw_bboxes(image, bboxes)\n",
    "\n",
    "    # Mostrar la imagen con los bboxes dibujados\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format(label_list))\n",
    "print(f\"largo: {len(label_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
