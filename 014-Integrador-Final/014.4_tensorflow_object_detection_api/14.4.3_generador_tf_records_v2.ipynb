{"cells":[{"cell_type":"markdown","metadata":{"id":"1I3-P0fWmveA"},"source":["#Modelo con TensorFlow OD API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ocLV-a2muVa","outputId":"6b114f10-ac69-4f9f-9921-07f6272d0767"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-06-22 13:14:12.787001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1750608852.965644  363764 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1750608853.016311  363764 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1750608853.453462  363764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1750608853.453506  363764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1750608853.453508  363764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1750608853.453510  363764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-06-22 13:14:13.503676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["#Importamos librerias Necesarias\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","#import seaborn as sns\n","import os\n","import re\n","import cv2\n","import random\n","from PIL import Image, ImageFilter, ImageDraw, ImageFont\n","#from IPython.display import Image as ImageDisplay\n","#from IPython.core.display import HTML\n","#from IPython.display import display, Image as IPImage\n","#from io import BytesIO\n","#import base64\n","#from sklearn.model_selection import train_test_split\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFMlFkuqnngt"},"outputs":[],"source":["imagenes_np = np.load('/home/garzamorada/my_character_detector_workspace/ocr_font_images_dataset.npy', allow_pickle=True)\n","imagenes_df = pd.read_csv('/home/garzamorada/my_character_detector_workspace/ocr_font_labels_dataset.csv')\n","path_tfrecord = '/home/garzamorada/my_character_detector_workspace/eval/tfrecord'\n","os.makedirs(path_tfrecord, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mdx5u1tuumJi"},"outputs":[],"source":["caracteres = \"ABCDEFGHIJKLMNOPQRSTUVWXYZÑabcdefghijklmnopqrstuvwxyzñáéíóúü0123456789.,;:?¿!¡-—&*/+=-_@#$%\"\n","\n","# Eliminar duplicados preservando orden\n","caracteres = ''.join(dict.fromkeys(caracteres))\n","\n","label_list = [{\"id\": idx, \"label\": c} for idx, c in enumerate(caracteres, start=1)]\n","\n","\n","def get_id_by_char(label, labels=label_list):\n","    for item in labels:\n","        if item[\"label\"] == label:\n","            return item[\"id\"]\n","    return None\n","\n","def generar_label_map(label_list, ruta_archivo):\n","    with open(ruta_archivo, 'w', encoding='utf-8') as f:\n","        for item in label_list:\n","            f.write(\"item {\\n\")\n","            f.write(f\"  id: {item['id']}\\n\")\n","            f.write(f\"  name: '{item['label']}'\\n\")\n","            f.write(\"}\\n\")\n","\n","generar_label_map(label_list, \"/home/garzamorada/my_character_detector_workspace/label_map.pbtxt\")"]},{"cell_type":"markdown","metadata":{"id":"o5YLZAJPoeuL"},"source":["## Generador de imagenes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9gTIUd-oxnu"},"outputs":[],"source":["# Generador de tfrecord\n","def guardar_imagen_y_tfrecord(imagen_np, bboxes, labels, chars, output_dir, nombre_base='img', idx=0):\n","    \"\"\"\n","    Guarda una imagen en disco y genera un archivo TFRecord correspondiente.\n","\n","    Args:\n","        imagen_np: np.ndarray (H, W) en escala de grises.\n","        bboxes: lista de bboxes en formato [xmin, ymin, xmax, ymax].\n","        labels: lista de strings de etiquetas correspondientes a cada bbox.\n","        output_dir: carpeta donde guardar los archivos.\n","        nombre_base: nombre base para los archivos (ej: 'img' → img_001.png).\n","        idx: índice numérico único para el nombre de archivo.\n","    \"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # 1. Guardar imagen en PNG\n","    filename = f'{nombre_base}_{idx:04d}.png'\n","    path_imagen = os.path.join(output_dir, filename)\n","    Image.fromarray(imagen_np).save(path_imagen)\n","\n","    # 2. Codificar imagen\n","    with tf.io.gfile.GFile(path_imagen, 'rb') as fid:\n","        encoded_image_data = fid.read()\n","    height, width = imagen_np.shape\n","\n","    # 3. Normalizar bboxes\n","    xmins = [box[0] / width for box in bboxes]\n","    xmaxs = [box[2] / width for box in bboxes]\n","    ymins = [box[1] / height for box in bboxes]\n","    ymaxs = [box[3] / height for box in bboxes]\n","    classes_text = [char.encode('utf8') for char in chars]\n","    classes_ids = labels\n","\n","    # 4. Crear TF Example\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n","        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n","        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n","        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n","        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n","        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'png'])),\n","        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n","        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n","        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n","        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n","        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n","        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes_ids)),\n","    }))\n","\n","    # 5. Guardar TFRecord\n","    tfrecord_path = os.path.join(output_dir, f'{nombre_base}_{idx:04d}.tfrecord')\n","    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n","        writer.write(tf_example.SerializeToString())\n","\n","    return path_imagen, tfrecord_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVefDkxS_yP0"},"outputs":[],"source":["def redimensionar_imagen_y_bbox(imagen_cv2, bbox, nuevo_ancho, nuevo_alto):\n","\n","    # Obtener las dimensiones originales de la imagen\n","    alto_original, ancho_original = imagen_cv2.shape[:2]\n","\n","    # Redimensionar la imagen\n","    imagen_redimensionada = cv2.resize(imagen_cv2, (nuevo_ancho, nuevo_alto), interpolation=cv2.INTER_AREA)\n","\n","    # Calcular los factores de escala\n","    factor_escala_ancho = nuevo_ancho / ancho_original\n","    factor_escala_alto = nuevo_alto / alto_original\n","\n","    # Ajustar las coordenadas del bounding box\n","    # Asumimos que bbox viene como (x_min, y_min, x_max, y_max)\n","    x_min_original, y_min_original, x_max_original, y_max_original = bbox\n","\n","    x_min_ajustado = int(x_min_original * factor_escala_ancho)\n","    y_min_ajustado = int(y_min_original * factor_escala_alto)\n","    x_max_ajustado = int(x_max_original * factor_escala_ancho)\n","    y_max_ajustado = int(y_max_original * factor_escala_alto)\n","\n","    bbox_ajustado = (x_min_ajustado, y_min_ajustado, x_max_ajustado, y_max_ajustado)\n","\n","    return imagen_redimensionada, bbox_ajustado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5XgSbqqGwwb"},"outputs":[],"source":["def generate_dataset(\n","    original_numpy_dataset,\n","    original_pandas_dataset,\n","    large_img_size=(320, 320),\n","    char_size=(128, 128), # Este es el tamaño fijo de tus caracteres originales\n","):\n","    global_composed_index = 0\n","    output_img_count = len(original_pandas_dataset)\n","\n","    new_w, new_h = large_img_size\n","\n","    if original_numpy_dataset.size == 0:\n","        print(\"El dataset de caracteres original está vacío. No se pueden generar imágenes compuestas.\")\n","        return np.array([], dtype=[('image', object), ('bboxes', object), ('index', int)]), pd.DataFrame()\n","\n","    for i in range(output_img_count):\n","        if ((global_composed_index + 1) * 100) % output_img_count == 0:\n","            print(f\"realizado {((global_composed_index + 1) * 100) // output_img_count}% \")\n","\n","        #char_entry = original_numpy_dataset[i]\n","        #char_index = char_entry['index']\n","        #char_data = original_pandas_dataset[original_pandas_dataset['index'] == char_index].iloc[0]\n","        char_data = original_pandas_dataset.iloc[i]\n","        index = char_data['index']\n","        char_entry = original_numpy_dataset[original_numpy_dataset['index'] == index][0]\n","\n","        char_label = char_data['character']\n","        id=get_id_by_char(char_label)\n","        char_image = char_entry['image']\n","        original_char_bbox = char_entry['bbox']\n","        new_char_image, new_char_bbox = redimensionar_imagen_y_bbox(char_image, original_char_bbox, new_w, new_h)\n","\n","        current_image_bboxes = []\n","        labels=[]\n","        chars=[]\n","        chars.append(char_label)\n","        labels.append(id)\n","        current_image_bboxes.append(new_char_bbox)\n","        ruta_imagen, ruta_record = guardar_imagen_y_tfrecord(new_char_image, current_image_bboxes, labels, chars, path_tfrecord, nombre_base='img', idx=global_composed_index)\n","\n","        global_composed_index += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5yLHfyxxNrM4","outputId":"225a8caa-ce60-41f4-b022-6ed805191527"},"outputs":[{"name":"stdout","output_type":"stream","text":["realizado 1% \n","realizado 2% \n","realizado 3% \n","realizado 4% \n","realizado 5% \n","realizado 6% \n","realizado 7% \n","realizado 8% \n","realizado 9% \n","realizado 10% \n","realizado 11% \n","realizado 12% \n","realizado 13% \n","realizado 14% \n","realizado 15% \n","realizado 16% \n","realizado 17% \n","realizado 18% \n","realizado 19% \n","realizado 20% \n","realizado 21% \n","realizado 22% \n","realizado 23% \n","realizado 24% \n","realizado 25% \n","realizado 26% \n","realizado 27% \n","realizado 28% \n","realizado 29% \n","realizado 30% \n","realizado 31% \n","realizado 32% \n","realizado 33% \n","realizado 34% \n","realizado 35% \n","realizado 36% \n","realizado 37% \n","realizado 38% \n","realizado 39% \n","realizado 40% \n","realizado 41% \n","realizado 42% \n","realizado 43% \n","realizado 44% \n","realizado 45% \n","realizado 46% \n","realizado 47% \n","realizado 48% \n","realizado 49% \n","realizado 50% \n","realizado 51% \n","realizado 52% \n","realizado 53% \n","realizado 54% \n","realizado 55% \n","realizado 56% \n","realizado 57% \n","realizado 58% \n","realizado 59% \n","realizado 60% \n","realizado 61% \n","realizado 62% \n","realizado 63% \n","realizado 64% \n","realizado 65% \n","realizado 66% \n","realizado 67% \n","realizado 68% \n","realizado 69% \n","realizado 70% \n","realizado 71% \n","realizado 72% \n","realizado 73% \n","realizado 74% \n","realizado 75% \n","realizado 76% \n","realizado 77% \n","realizado 78% \n","realizado 79% \n","realizado 80% \n","realizado 81% \n","realizado 82% \n","realizado 83% \n","realizado 84% \n","realizado 85% \n","realizado 86% \n","realizado 87% \n","realizado 88% \n","realizado 89% \n","realizado 90% \n","realizado 91% \n","realizado 92% \n","realizado 93% \n","realizado 94% \n","realizado 95% \n","realizado 96% \n","realizado 97% \n","realizado 98% \n","realizado 99% \n","realizado 100% \n"]}],"source":["# Parámetros para la generación de imágenes compuestas\n","#num_composed_images_to_generate = 5000 # Define cuántas imágenes grandes quieres generar\n","output_large_img_size = (320, 320)\n","input_char_size = (128, 128) # Tamaño fijo de tus caracteres de origen\n","original_numpy_dataset= imagenes_np\n","#original_pandas_dataset= imagenes_df.sample(5000) #Para eval\n","original_pandas_dataset= imagenes_df\n","\n","generate_dataset(\n","    original_numpy_dataset,\n","    original_pandas_dataset,\n","    large_img_size=output_large_img_size,\n","    char_size=input_char_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xia3izlX_yP2"},"outputs":[],"source":["print(format(label_list))\n","print(f\"largo: {len(label_list)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTInmyAd_yP3"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"}},"nbformat":4,"nbformat_minor":0}