{"cells":[{"cell_type":"markdown","metadata":{"id":"g7IPG7fi_LpS"},"source":["# Detector de Texto para OCR\n","Este modelo pretende detectar la resencia de texto en una imagen y en lo posible retornar las lineas de texto y cajas de los carcteres que las componen.\n","\n","Modelo basado en yolo 8"]},{"cell_type":"markdown","metadata":{"id":"TuOm6D1jAZVP"},"source":["## Importación de Librerias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnPgMHzkkUQB"},"outputs":[],"source":["#!pip install -q ultralytics\n","from ultralytics import YOLO"]},{"cell_type":"code","source":["#!pip install pandas numpy seaborn matplotlib scikit-learn pillow opencv-python IPython"],"metadata":{"id":"wM06rzCgrO7V"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3Me7qvf_FbB"},"outputs":[],"source":["#Importo librerias a utilizar\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import re\n","import cv2\n","import random\n","from PIL import Image, ImageFilter\n","from IPython.display import Image as ImageDisplay\n","from IPython.core.display import HTML\n","from io import BytesIO\n","import base64\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Df0azrQHBDo8"},"outputs":[],"source":["# Funciones auxiliares\n","def np_to_base64_img(arr):\n","    \"\"\"Convierte un np.array a una imagen embebida en base64\"\"\"\n","    h,w = arr.shape[:2]\n","    im = Image.fromarray(arr)\n","    buffer = BytesIO()\n","    im.save(buffer, format=\"PNG\")\n","    img_str = base64.b64encode(buffer.getvalue()).decode()\n","    return f'<img src=\"data:image/png;base64,{img_str}\" width=\"{w}\" height=\"{h}\"/>'"]},{"cell_type":"markdown","metadata":{"id":"W_NADV3yBhki"},"source":["## Dataset de entrenamiento\n","Este dataset contendra imagenes de carcateres y las coordenadas de la caja que los contiene"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7SJ28ePB8up"},"outputs":[],"source":["def get_bbox_from_image(image_array):\n","    \"\"\"\n","    Toma un array NumPy de una imagen en escala de grises, encuentra los contornos,\n","    los combina y devuelve las coordenadas de la bounding box en formato\n","    (x_min, y_min, x_max, y_max).\n","\n","    Args:\n","        image_array (np.ndarray): Una imagen en escala de grises como un array NumPy.\n","\n","    Returns:\n","        tuple: Una tupla (x_min, y_min, x_max, y_max) que representa la bounding box.\n","               Retorna None si no se encuentran contornos.\n","    \"\"\"\n","    # Asegurarse de que la imagen esté en escala de grises si no lo está ya\n","    if len(image_array.shape) == 3:\n","        gray_image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n","    else:\n","        gray_image = image_array\n","\n","    # Binarizar la imagen si es necesario para asegurar buenos contornos\n","    # Esto es crucial si la imagen de entrada tiene tonos de gris en lugar de solo blanco/negro\n","    # Ajusta el umbral (e.g., 127) y el tipo (e.g., cv2.THRESH_BINARY_INV) según tus imágenes.\n","    _, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","\n","\n","    # Encontrar contornos\n","    # cv2.RETR_EXTERNAL recupera solo los contornos externos (útil para caracteres con agujeros internos)\n","    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    if not contours:\n","        binary_image=cv2.bitwise_not(binary_image)\n","        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        if not contours:\n","            return None # No se encontraron contornos\n","\n","    # Combinar todos los contornos en uno solo (para caracteres con múltiples partes como 'i' o 'j')\n","    # Solo apilamos si hay contornos válidos (size > 0)\n","    valid_contours = [c.squeeze() for c in contours if c.size > 0]\n","    if not valid_contours:\n","        return None # No se encontraron contornos válidos después de limpiar\n","\n","    all_points = np.vstack(valid_contours)\n","\n","    # Encontrar el rectángulo delimitador para el contorno combinado\n","    x, y, w, h = cv2.boundingRect(all_points)\n","\n","    # Retornar en el formato (x_min, y_min, x_max, y_max)\n","    x_min, y_min = x, y\n","    x_max, y_max = x + w, y + h\n","\n","    return (x_min, y_min, x_max, y_max)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lp60eimwA8nF"},"outputs":[],"source":["# Cargar los datos del archivo npz\n","data = np.load(fr\"C:\\Users\\Andres\\Downloads\\unified_dataset.npz\", allow_pickle=True)\n","\n","print(format(data))\n","images = data['images']\n","bboxes = data['bboxes']\n","\n","# Crear un DataFrame de pandas\n","df = pd.DataFrame({'image': list(images), 'bbox':list(bboxes)})\n","\n","# Aplicar la función np_to_base64_img a la columna 'image'\n","df['imagen_base64'] = df['image'].apply(np_to_base64_img)\n","df['bbox'] = df['image'].apply(get_bbox_from_image)\n","\n","# Mostrar las primeras filas del nuevo DataFrame\n","print(df.head())"]},{"cell_type":"markdown","metadata":{"id":"iA_E3_zxHEEz"},"source":["## Funciones de transformación para aumentado de datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6J8BBpj4HJq6"},"outputs":[],"source":["# --- Funciones auxiliares para transformar bounding boxes ---\n","\n","def get_corners_from_bbox(bbox):\n","    \"\"\"Convierte (x_min, y_min, x_max, y_max) a 4 puntos de esquina.\"\"\"\n","    x_min, y_min, x_max, y_max = bbox\n","    return np.array([\n","        [x_min, y_min],\n","        [x_max, y_min],\n","        [x_max, y_max],\n","        [x_min, y_max]\n","    ], dtype=np.float32)\n","\n","def get_bbox_from_corners(corners, image_shape):\n","    \"\"\"\n","    Calcula la nueva bbox (x_min, y_min, x_max, y_max) a partir de 4 puntos de esquina transformados,\n","    asegurándose de que la bbox esté dentro de los límites de la imagen.\n","    \"\"\"\n","    height, width = image_shape[:2]\n","\n","    x_coords = corners[:, 0]\n","    y_coords = corners[:, 1]\n","\n","    x_min = np.min(x_coords)\n","    y_min = np.min(y_coords)\n","    x_max = np.max(x_coords)\n","    y_max = np.max(y_coords)\n","\n","    # Asegurarse de que las coordenadas estén dentro de los límites de la imagen\n","    x_min = max(0, int(x_min))\n","    y_min = max(0, int(y_min))\n","    x_max = min(width - 1, int(x_max))\n","    y_max = min(height - 1, int(y_max))\n","\n","    # Asegurarse de que la caja sea válida (x_max >= x_min, y_max >= y_min)\n","    if x_max < x_min: x_max = x_min\n","    if y_max < y_min: y_max = y_min\n","\n","    return (x_min, y_min, x_max, y_max)\n","\n","# --- Funciones de Rotación, Escala y Perspectiva Modificadas ---\n","\n","# Rotación\n","def rotar_imagen(imagen_np_array, bbox, angulo_rotacion_min, angulo_rotacion_max):\n","    \"\"\"\n","    Rota una imagen y su bounding box asociada.\n","    La imagen de entrada debe ser un NumPy array.\n","    La bbox de entrada es (x_min, y_min, x_max, y_max).\n","    Devuelve la imagen rotada (NumPy array) y la nueva bbox.\n","    \"\"\"\n","    img = Image.fromarray(imagen_np_array)\n","    ancho_original, alto_original = img.size\n","\n","    # Aplico una rotación aleatoria dentro del rango permitido\n","    angulos_rotacion_opciones = [0, 0, random.uniform(angulo_rotacion_min, angulo_rotacion_max)]\n","    angulo_rotacion = random.choice(angulos_rotacion_opciones)\n","\n","    # Rota la imagen, expandiendo el lienzo para que no se corte\n","    imagen_rotada_pil = img.rotate(angulo_rotacion, resample=Image.Resampling.BILINEAR, expand=True)\n","    imagen_rotada_np = np.array(imagen_rotada_pil)\n","\n","    # Calcular la matriz de rotación para los puntos de la bbox\n","    # El centro de rotación cambia si expandimos la imagen\n","    ancho_nuevo, alto_nuevo = imagen_rotada_pil.size\n","    # Desplazamiento del centro (el centro de la imagen original se mueve al nuevo centro)\n","    dx = (ancho_nuevo - ancho_original) / 2\n","    dy = (alto_nuevo - alto_original) / 2\n","\n","    # Matriz de rotación con traslación para el centro original\n","    M_rot = cv2.getRotationMatrix2D((ancho_original / 2, alto_original / 2), angulo_rotacion, 1.0)\n","    # Aplicar el desplazamiento para el nuevo tamaño de lienzo\n","    M_rot[0, 2] += dx\n","    M_rot[1, 2] += dy\n","\n","    # Transformar las esquinas de la bbox\n","    bbox_corners = get_corners_from_bbox(bbox)\n","    # cv2.transform necesita los puntos en formato [N, 1, 2]\n","    transformed_corners = cv2.transform(bbox_corners.reshape(-1, 1, 2), M_rot).reshape(-1, 2)\n","\n","    # Calcular la nueva bbox a partir de las esquinas transformadas\n","    nueva_bbox = get_bbox_from_corners(transformed_corners, imagen_rotada_np.shape)\n","\n","    return imagen_rotada_np, nueva_bbox\n","\n","# Perspectiva Vertical\n","def aplicar_perspectiva_vertical(imagen_np_array, bbox, factor, top=True):\n","    \"\"\"\n","    Aplica una transformación de perspectiva vertical a una imagen y su bounding box.\n","    La imagen de entrada debe ser un NumPy array (BGR o escala de grises).\n","    La bbox de entrada es (x_min, y_min, x_max, y_max).\n","    Devuelve la imagen con perspectiva y la nueva bbox.\n","    \"\"\"\n","    height, width = imagen_np_array.shape[:2]\n","\n","    # Puntos originales de la imagen (esquinas)\n","    pts1_img = np.float32([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]])\n","\n","    # Puntos de destino para la imagen\n","    pts2_img = np.copy(pts1_img)\n","\n","    if 0 <= factor <= 1:\n","        if top:\n","            new_top_left_x = int(width * (1 - factor) / 2)\n","            new_top_right_x = width - 1 - new_top_left_x\n","            pts2_img[0] = [new_top_left_x, 0]\n","            pts2_img[1] = [new_top_right_x, 0]\n","        else:\n","            new_bottom_left_x = int(width * (1 - factor) / 2)\n","            new_bottom_right_x = width - 1 - new_bottom_left_x\n","            pts2_img[2] = [new_bottom_right_x, height - 1]\n","            pts2_img[3] = [new_bottom_left_x, height - 1]\n","    else:\n","        print(\"Advertencia: El factor de perspectiva debe estar entre 0 y 1. No se aplicó la transformación.\")\n","        return imagen_np_array, bbox\n","\n","    # Obtener la matriz de transformación de perspectiva\n","    M_perspectiva = cv2.getPerspectiveTransform(pts1_img, pts2_img)\n","\n","    # Aplicar la transformación de perspectiva a la imagen\n","    imagen_con_perspectiva = cv2.warpPerspective(imagen_np_array, M_perspectiva, (width, height))\n","\n","    # Transformar las esquinas de la bbox usando la misma matriz\n","    bbox_corners = get_corners_from_bbox(bbox)\n","    transformed_corners = cv2.perspectiveTransform(bbox_corners.reshape(-1, 1, 2), M_perspectiva).reshape(-1, 2)\n","\n","    # Calcular la nueva bbox a partir de las esquinas transformadas\n","    nueva_bbox = get_bbox_from_corners(transformed_corners, imagen_con_perspectiva.shape)\n","\n","    return imagen_con_perspectiva, nueva_bbox\n","\n","# Perspectiva Horizontal\n","def aplicar_perspectiva_horizontal(imagen_np_array, bbox, factor, left=True):\n","    \"\"\"\n","    Aplica una transformación de perspectiva horizontal a una imagen y su bounding box.\n","    La imagen de entrada debe ser un NumPy array (BGR o escala de grises).\n","    La bbox de entrada es (x_min, y_min, x_max, y_max).\n","    Devuelve la imagen con perspectiva y la nueva bbox.\n","    \"\"\"\n","    height, width = imagen_np_array.shape[:2]\n","\n","    # Puntos originales de la imagen (esquinas)\n","    pts1_img = np.float32([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]])\n","\n","    # Puntos de destino para la imagen\n","    pts2_img = np.copy(pts1_img)\n","\n","    if 0 <= factor <= 1:\n","        if left:\n","            new_top_left_y = int(height * (1 - factor) / 2)\n","            new_bottom_left_y = height - 1 - new_top_left_y\n","            pts2_img[0] = [0, new_top_left_y]\n","            pts2_img[3] = [0, new_bottom_left_y]\n","        else:\n","            new_top_right_y = int(height * (1 - factor) / 2)\n","            new_bottom_right_y = height - 1 - new_top_right_y\n","            pts2_img[1] = [width - 1, new_top_right_y]\n","            pts2_img[2] = [width - 1, new_bottom_right_y]\n","    else:\n","        print(\"Advertencia: El factor de perspectiva debe estar entre 0 y 1. No se aplicó la transformación.\")\n","        return imagen_np_array, bbox\n","\n","    # Obtener la matriz de transformación de perspectiva\n","    M_perspectiva = cv2.getPerspectiveTransform(pts1_img, pts2_img)\n","\n","    # Aplicar la transformación de perspectiva a la imagen\n","    imagen_con_perspectiva = cv2.warpPerspective(imagen_np_array, M_perspectiva, (width, height))\n","\n","    # Transformar las esquinas de la bbox usando la misma matriz\n","    bbox_corners = get_corners_from_bbox(bbox)\n","    transformed_corners = cv2.perspectiveTransform(bbox_corners.reshape(-1, 1, 2), M_perspectiva).reshape(-1, 2)\n","\n","    # Calcular la nueva bbox a partir de las esquinas transformadas\n","    nueva_bbox = get_bbox_from_corners(transformed_corners, imagen_con_perspectiva.shape)\n","\n","    return imagen_con_perspectiva, nueva_bbox\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HBZM-NgrcoW"},"outputs":[],"source":["# prompt: quiero una funcion que rescale la imagen a 32x32 si fuera mas grande la imagen y ajuste el bbox a ese tamaño en ese caso\n","\n","def rescale_image_and_bbox(image_np_array, bbox, target_size=(32, 32)):\n","    \"\"\"\n","    Rescala una imagen a un tamaño objetivo si es más grande y ajusta la bounding box.\n","\n","    Args:\n","        image_np_array (np.ndarray): La imagen como un array NumPy.\n","        bbox (tuple): La bounding box en formato (x_min, y_min, x_max, y_max).\n","        target_size (tuple): El tamaño objetivo para la imagen (ancho, alto).\n","\n","    Returns:\n","        tuple: Una tupla (rescaled_image, rescaled_bbox).\n","               retorna la imagen y bbox originales si la imagen no es más grande que target_size.\n","               retorna None, None si la imagen no tiene una bbox válida.\n","    \"\"\"\n","\n","    current_height, current_width = image_np_array.shape[:2]\n","    target_width, target_height = target_size\n","\n","    # Solo rescalar si la imagen es más grande que el tamaño objetivo en alguna dimensión\n","    if current_width > target_width or current_height > target_height:\n","        # Calcular el factor de escala\n","        scale_w = target_width / current_width\n","        scale_h = target_height / current_height\n","\n","        # Rescalar la imagen usando cv2.resize\n","        rescaled_image = cv2.resize(image_np_array, target_size, interpolation=cv2.INTER_AREA)\n","\n","        # Ajustar la bounding box\n","        x_min, y_min, x_max, y_max = bbox\n","        rescaled_bbox = (\n","            int(x_min * scale_w),\n","            int(y_min * scale_h),\n","            int(x_max * scale_w),\n","            int(y_max * scale_h)\n","        )\n","\n","        return rescaled_image, rescaled_bbox\n","    else:\n","        # No necesita rescalar, retornar original\n","        return image_np_array, bbox\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_OFUoGKHPv6"},"outputs":[],"source":["#Funciones de ruido\n","# Ruido de Sal\n","def add_salt_and_pepper_noise(image, prob):\n","    \"\"\"Agrega ruido de sal y pimienta a una imagen PIL.\"\"\"\n","    img_array = np.array(image)\n","    output = np.copy(img_array)\n","    black = 0\n","    white = 255\n","    height, width, channels = img_array.shape if len(img_array.shape) == 3 else (img_array.shape[0], img_array.shape[1], 1)\n","\n","    for i in range(height):\n","        for j in range(width):\n","            if random.random() < prob:\n","                if random.random() < 0.5:\n","                    output[i][j] = black\n","                else:\n","                    output[i][j] = white\n","    return output\n","\n","# Desenfoque\n","def add_gaussian_blur(imagen_gris_cv2, radius):\n","    \"\"\"Aplica desenfoque gaussiano a una imagen CV2 en escala de grises.\"\"\"\n","    # cv2.GaussianBlur espera un tamaño de kernel impar y positivo\n","    # Asegurarse de que el tamaño del kernel sea impar y al menos 1\n","    kernel_size = int(radius * 2) + 1\n","    if kernel_size % 2 == 0: # Si es par, hacerlo impar\n","        kernel_size += 1\n","    kernel_size = max(1, kernel_size) # Asegurarse de que sea al menos 1\n","    return cv2.GaussianBlur(imagen_gris_cv2, (kernel_size, kernel_size), 0)\n","\n","def add_motion_blur(imagen_gris_cv2, radius, angle):\n","    \"\"\"Aplica desenfoque de movimiento a una imagen CV2 en escala de grises.\"\"\"\n","    longitud = int(radius)\n","    if longitud == 0:\n","        return imagen_gris_cv2\n","\n","    kernel = np.zeros((longitud, longitud), dtype=np.float32)\n","    center = longitud // 2\n","    # Crear una línea horizontal para simular el movimiento\n","    cv2.line(kernel, (0, center), (longitud - 1, center), 1, 1)\n","\n","    # Rotar el kernel\n","    M = cv2.getRotationMatrix2D((center, center), angle, 1.0)\n","    kernel = cv2.warpAffine(kernel, M, (longitud, longitud), flags=cv2.INTER_LINEAR)\n","    kernel = kernel / (np.sum(kernel) + 1e-6) # Normalizar y evitar división por cero\n","\n","    output = cv2.filter2D(imagen_gris_cv2, -1, kernel)\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7gfsl3QHUvJ"},"outputs":[],"source":["# Funciones de variacion del color\n","def ajustar_brillo(imagen_gris_cv2, valor_brillo):\n","    \"\"\"Ajusta el brillo de una imagen CV2 en escala de grises.\"\"\"\n","    # Usando np.clip con operaciones aritméticas directas de NumPy para mayor robustez.\n","    return np.clip(imagen_gris_cv2.astype(np.int16) + valor_brillo, 0, 255).astype(np.uint8)\n","\n","def ajustar_contraste(imagen_gris, factor_contraste):\n","    # Asegura que el factor de contraste sea positivo\n","    factor_clipeado = max(0.0, factor_contraste)\n","\n","    # Aplica el ajuste de contraste\n","    # Convertir a float para evitar problemas con la multiplicación y luego a uint8\n","    imagen_float = imagen_gris.astype(np.float32)\n","\n","    # Fórmula: alpha * pixel_value + beta (donde beta = 128 * (1 - alpha) para mantener el punto medio)\n","    # Sin embargo, la forma más directa es como la fórmula mencionada: alpha * (P - medio) + medio\n","    # OpenCV's convertScaleAbs hace (alpha * src + beta)\n","    # Para la fórmula de contraste que dimos, beta sería: 128 * (1 - factor_contraste)\n","\n","    imagen_ajustada = cv2.convertScaleAbs(imagen_float, alpha=factor_clipeado, beta=128 * (1 - factor_clipeado))\n","\n","    return imagen_ajustada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KVQc6tKHbzB"},"outputs":[],"source":["def aplicar_transformacion_aleatoria(imagen_cv2, bbox):\n","    \"\"\"\n","    Decide si aplicar transformaciones (50% de probabilidad) y, si lo hace,\n","    aplica entre 1 y 3 transformaciones aleatorias.\n","    Todas las transformaciones reciben y devuelven imágenes CV2 en escala de grises.\n","\n","    Args:\n","        imagen_cv2 (np.ndarray): La imagen de entrada en formato numpy array (BGR o escala de grises).\n","\n","    Returns:\n","        np.ndarray: La imagen transformada o la original, siempre en escala de grises (CV2).\n","    \"\"\"\n","    # Primero, asegurar que la imagen de entrada esté en escala de grises\n","    if len(imagen_cv2.shape) == 3:\n","        imagen_gris_original = cv2.cvtColor(imagen_cv2, cv2.COLOR_BGR2GRAY)\n","    else:\n","        imagen_gris_original = imagen_cv2.copy() # Copia para no modificar la original\n","\n","    # 50% de probabilidad de no aplicar ninguna transformación\n","    #if random.random() < 0.5:\n","    #    return imagen_gris_original, bbox # Devuelve la imagen original en escala de grises y la caja original\n","\n","    # Si llegamos aquí, vamos a aplicar transformaciones\n","    imagen_actual = imagen_gris_original # Empezamos con la versión gris de la imagen\n","\n","    # Lista de transformaciones disponibles (TODAS operan en CV2 gris y devuelven CV2 gris)\n","    transformaciones_disponibles = [\n","        # Las funciones deben ser las versiones que reciben/devuelven CV2 gris\n","        {'func': add_salt_and_pepper_noise, 'params': {'prob': random.uniform(0.005, 0.03)}},\n","        {'func': add_gaussian_blur, 'params': {'radius': random.uniform(0.5, 1.5)}},\n","        {'func': add_motion_blur, 'params': {'radius': random.randint(5, 15), 'angle': random.uniform(0, 360)}},\n","        {'func': rotar_imagen, 'params': {'bbox': bbox, 'angulo_rotacion_min': -5, 'angulo_rotacion_max': 5}},\n","        {'func': aplicar_perspectiva_vertical, 'params': {'bbox': bbox, 'factor': random.uniform(0.05, 0.2), 'top': random.choice([True, False])}},\n","        {'func': aplicar_perspectiva_horizontal, 'params': {'bbox': bbox, 'factor': random.uniform(0.05, 0.2), 'left': random.choice([True, False])}},\n","        {'func': ajustar_brillo, 'params': {'valor_brillo': random.randint(-30, 30)}},\n","        {'func': ajustar_contraste, 'params': {'factor_contraste': random.uniform(0.8, 1.2)}},\n","    ]\n","\n","    # Elegir entre 1 y 3 transformaciones para aplicar\n","    num_transformaciones = random.randint(1, 3)\n","    # Usamos random.sample para elegir funciones únicas si num_transformaciones es menor que la lista completa\n","    transformaciones_a_aplicar = random.sample(transformaciones_disponibles, num_transformaciones)\n","\n","    for trans_info in transformaciones_a_aplicar:\n","        func = trans_info['func']\n","        params = trans_info['params']\n","\n","        try:\n","            # Todas las funciones ahora reciben y devuelven CV2 en escala de grises\n","            resultado = func(imagen_actual, **params)\n","            if isinstance(resultado, tuple) and len(resultado) == 2:\n","                imagen_actual, bbox = resultado\n","            else:\n","                imagen_actual = resultado\n","        except Exception as e:\n","            print(f\"Error al aplicar la transformación '{func.__name__}': {e}. Se mantiene la imagen actual para la siguiente transformación.\")\n","\n","    return imagen_actual, bbox"]},{"cell_type":"markdown","metadata":{"id":"3lVGA3CPoK2u"},"source":["## Generacion de archivos de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhEetPt8oSC4"},"outputs":[],"source":["os.makedirs('c:/tmp/content/training/images/train', exist_ok=True)\n","os.makedirs('c:/tmp/content/training/images/val', exist_ok=True)\n","os.makedirs('c:/tmp/content/training/labels/train', exist_ok=True)\n","os.makedirs('c:/tmp/content/training/labels/val', exist_ok=True)\n","\n","indices = df.index.to_list()\n","train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n","\n","def save_image_and_label(idx, image, bbox, split):\n","    img_path = f'c:/tmp/content/training/images/{split}/{idx}.jpg'\n","    label_path = f'c:/tmp/content/training/labels/{split}/{idx}.txt'\n","\n","    img = Image.fromarray((image * 255).astype('uint8')).convert('L')\n","    img.save(img_path)\n","\n","    h, w = image.shape\n","    x_min, y_min, x_max, y_max = bbox\n","\n","    # YOLO format: class x_center y_center width height (normalized)\n","    xc = (x_min + x_max) / 2 / w\n","    yc = (y_min + y_max) / 2 / h\n","    bw = (x_max - x_min) / w\n","    bh = (y_max - y_min) / h\n","\n","    with open(label_path, 'w') as f:\n","        f.write(f'0 {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\\n')\n","\n","for idx, row in df.iterrows():\n","    split = 'train' if idx in train_idx else 'val'\n","    image, bbox = rescale_image_and_bbox(row['image'], row['bbox'])\n","    save_image_and_label(idx, image, bbox, split)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MverYIenqLsM"},"outputs":[],"source":["with open(\"data.yaml\", \"w\") as f:\n","    f.write(\"\"\"\n","path: c:/tmp/content/training\n","train: images/train\n","val: images/val\n","names: ['char']\n","\"\"\")"]},{"cell_type":"markdown","metadata":{"id":"DwXkdTkktMLm"},"source":["## Entrenamiento del Modelo YOLO 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjVSqIQctRqW"},"outputs":[],"source":["model = YOLO('yolov8n.pt')  # También podés usar yolov8s.pt para más precisión\n","\n","model.train(\n","    data='data.yaml',\n","    epochs=20,\n","    imgsz=32,\n","    batch=64,\n","    show=True,\n","    augment=True\n",")"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}